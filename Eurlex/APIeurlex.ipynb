{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'eur-lex.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'eur-lex.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'eur-lex.europa.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from eurlex_api import *\n",
    "from azure_api_test import *\n",
    "\n",
    "url_api_AML5 ='https://eur-lex.europa.eu/legal-content/FR/TXT/HTML/?uri=CELEX:02015L0849-20240709'\n",
    "url_api_AML6 = 'https://eur-lex.europa.eu/legal-content/FR/TXT/HTML/?uri=OJ:L_202401640'\n",
    "url_api_R_AML6 = 'https://eur-lex.europa.eu/legal-content/FR/TXT/HTML/?uri=OJ:L_202401689'\n",
    "api_result_AML5 = get_api_result(url_api_AML5)\n",
    "api_result_AML6 = get_api_result(url_api_AML6)\n",
    "api_result_R_AML6 = get_api_result(url_api_R_AML6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for elem in api_result_AML5:\n",
    "        soup = BeautifulSoup(elem['content'], 'html.parser')\n",
    "        text = get_content_from_html(soup)\n",
    "#display(HTML(elem['content']))\n",
    "print(type(elem['content']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art_1\n",
      "{'message': 'Fonction html_json appelée avec succès', 'html': \"\\nArticle premier\\n\\n1.\\xa0\\xa0\\nLa présente directive vise à prévenir l'utilisation du système financier de l'Union aux fins du blanchiment de capitaux et du financement du terrorisme.\\n\\n\\n2.\\xa0\\xa0\\nLes États membres veillent à ce que le blanchiment de capitaux et le financement du terrorisme soient interdits.\\n\\n\\n3.\\xa0\\xa0\\n\\nAux fins de la présente directive, sont considérés comme blanchiment de capitaux les\\xa0agissements ci-après énumérés, commis intentionnellement:\\n\\n\\na)\\xa0\\n\\n\\nla conversion ou le transfert de biens, dont celui qui s'y livre sait qu'ils proviennent d'une activité criminelle ou d'une participation à une activité criminelle, dans le but de dissimuler ou de déguiser l'origine illicite de ces biens ou d'aider toute personne impliquée dans une telle activité à échapper aux\\xa0conséquences juridiques des actes qu'elle a commis;\\n\\n\\n\\n\\nb)\\xa0\\n\\n\\nle fait de dissimuler ou de déguiser la nature, l'origine, l'emplacement, la disposition, le mouvement ou la propriété réels de biens ou des droits qui y sont liés, dont celui qui s'y livre sait qu'ils proviennent d'une activité criminelle ou d'une participation à une telle activité;\\n\\n\\n\\n\\nc)\\xa0\\n\\n\\nl'acquisition, la détention ou l'utilisation de biens, dont celui qui s'y livre sait, au moment où il les réceptionne, qu'ils proviennent d'une activité criminelle ou d'une participation à une telle activité;\\n\\n\\n\\n\\nd)\\xa0\\n\\n\\nla participation à l'un des actes visés aux points\\xa0a), b) et\\xa0c), le fait de s'associer pour le\\xa0commettre, de tenter de le commettre, d'aider ou d'inciter quelqu'un à le commettre ou de\\xa0le\\xa0conseiller à cet effet, ou de faciliter l'exécution d'un tel acte.\\n\\n\\n\\n\\n\\n4.\\xa0\\xa0\\nIl y a blanchiment de capitaux même si les activités qui sont à l'origine des biens à blanchir ont été exercées sur le territoire d'un autre État membre ou sur celui d'un pays tiers.\\n\\n\\n5.\\xa0\\xa0\\nAux fins de la présente directive, on entend par «financement du terrorisme» le fait de fournir ou de réunir des fonds, par quelque moyen que ce soit, directement ou indirectement, dans l'intention de les voir utilisés ou en sachant qu'ils seront utilisés, en tout ou en partie, en vue de commettre l'une quelconque des infractions visées aux articles\\xa01er à\\xa04 de la décision-cadre\\xa02002/475/JAI du Conseil\\xa0(\\n1\\n).\\n\\n\\n6.\\xa0\\xa0\\nLa connaissance, l'intention ou la motivation requises pour qualifier les actes visés aux\\xa0paragraphes\\xa03 et\\xa05 peuvent être déduites de circonstances de fait objectives.\\n\\n\"}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(article_id)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(html_json(article\u001b[38;5;241m.\u001b[39mget_text()))\n\u001b[0;32m---> 21\u001b[0m     json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Nom du fichier où vous voulez sauvegarder le JSON\u001b[39;00m\n\u001b[1;32m     23\u001b[0m fichier_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticles_AML5.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not dict"
     ]
    }
   ],
   "source": [
    "# Chaîne JSON\n",
    "json_data = {\n",
    "    \"articles\": []\n",
    "}\n",
    "\n",
    "# Parser le HTML\n",
    "soup = BeautifulSoup(elem['content'], 'html.parser')\n",
    "\n",
    "# Trouver toutes les subdivisions\n",
    "articles = soup.find_all('div', class_='eli-subdivision')\n",
    "\n",
    "data = []\n",
    "\n",
    "for article in articles:\n",
    "    # Vérifier si c'est un article (ID contient 'art_')\n",
    "    article_id = article.get('id', '')\n",
    "    if not article_id.startswith('art_'):\n",
    "        continue\n",
    "    print(article_id)\n",
    "    json_data[\"articles\"].append(json.loads(html_json(article.get_text())))\n",
    "# Nom du fichier où vous voulez sauvegarder le JSON\n",
    "fichier_json = \"articles_AML5.json\"\n",
    "\n",
    "# Écriture dans le fichier\n",
    "with open(fichier_json, \"w\", encoding=\"utf-8\") as fichier:\n",
    "    json.dump(json_data, fichier, ensure_ascii=False, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier JSON a été écrit avec succès : tableau_correspondance.json\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "json_data = {\n",
    "    \"Table_correspondance\": [\n",
    "    ] \n",
    "}\n",
    "\n",
    "# Parser le HTML\n",
    "soup = BeautifulSoup(elem['content'], 'html.parser')\n",
    "\n",
    "# Extraire le titre de l'article\n",
    "containers = soup.find_all('div', class_='eli-container')\n",
    "\n",
    "# Extraire les données des paragraphes\n",
    "for container in containers:\n",
    "    if \"Tableau de correspondance\" in container.get_text():\n",
    "        oj_tables = container.find_all('tr', class_='oj-table')\n",
    "        for oj_table in oj_tables:\n",
    "            oj_tbl_arts = oj_table.find_all('p', class_='oj-tbl-txt')\n",
    "            entry = []\n",
    "            for oj_tbl_art in oj_tbl_arts:\n",
    "                text = oj_tbl_art.get_text().strip()  # Extraire et nettoyer le texte\n",
    "                entry.append(text)\n",
    "            # Ajouter l'entrée au JSON\n",
    "            if entry:  # Ajouter uniquement si non vide\n",
    "                json_data[\"Table_correspondance\"].append(entry)\n",
    "fichier_json = \"tableau_correspondance.json\"\n",
    "with open(fichier_json, \"w\", encoding=\"utf-8\") as fichier:\n",
    "    json.dump(json_data, fichier, indent=4, ensure_ascii=False)\n",
    "print(f\"Le fichier JSON a été écrit avec succès : {fichier_json}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Parser le HTML\n",
    "soup = BeautifulSoup(elem['content'], 'html.parser')\n",
    "\n",
    "# Extraire le titre de l'article\n",
    "article_titles = soup.find_all('p', class_='title-article-norm')\n",
    "\n",
    "# Extraire les données des paragraphes\n",
    "data = []\n",
    "for article_title in article_titles:\n",
    "    paragraphs = soup.find_all('div', class_='norm', recursive=True)\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        paragraph_number_tag = paragraph.find('span', class_='no-parag')\n",
    "        paragraph_number = paragraph_number_tag.text.strip() if paragraph_number_tag else None\n",
    "\n",
    "        # Vérifier les sous-paragraphes\n",
    "        sub_paragraphs = paragraph.find_all('div', class_='grid-container')\n",
    "        if sub_paragraphs:\n",
    "            for sub in sub_paragraphs:\n",
    "                sub_number = sub.find('span').text.strip() if sub.find('span') else None\n",
    "                sub_content = sub.find('div', class_='grid-list-column-2').text.strip() if sub.find('div', class_='grid-list-column-2') else None\n",
    "                data.append([article_title, paragraph_number, sub_number, sub_content])\n",
    "        else:\n",
    "            # Aucun sous-paragraphe trouvé\n",
    "            content = paragraph.find('div', class_='norm inline-element').text.strip() if paragraph.find('div', class_='norm inline-element') else None\n",
    "            data.append([article_title, paragraph_number, None, content])\n",
    "\n",
    "# Convertir en DataFrame pour un affichage structuré\n",
    "df = pd.DataFrame(data, columns=['Article', 'Paragraphe', 'Sous-paragraphe', 'Contenu'])\n",
    "\n",
    "# Afficher le tableau\n",
    "print(df.dropna(subset='Paragraphe'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
